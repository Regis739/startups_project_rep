{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqlZrA05IwQw"
      },
      "source": [
        "# Создание модель машинного обучения для предсказании неудач стартапов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5-_Fp46JhPT"
      },
      "source": [
        "## Описание проекта"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaBk4tpATiRI"
      },
      "source": [
        "Построение бизнеса – непростая задача. Все начинается с идеи, которая может помочь решить проблему, с которой сталкиваются люди. Но даже с самой лучшей и инновационной идеей вы не сможете продвинуться достаточно далеко, если у вас нет достаточной финансовой поддержки. Если стартапу не удастся получить достаточную поддержку, особенно на ранней стадии, ему придется закрыться. В 2022 году отсутствие финансирования привело к неудачам 47% стартапов.\n",
        "Финансирование — это жизненно важная вещь, в которой нуждается стартап, и оно состоит из множества этапов, называемых раундами финансирования (funding rounds):\n",
        "- pre-seed funding, вероятно, самый важный раунд, на котором компания пускает корни\n",
        "- first seed funding, на котором компания должна создать фундамент, на котором она стремится иметь устойчивое будущее.\n",
        "- series A funding. В течение этого периода привилегированные акции продаются инвесторам, которые желают принимать более активное участие в их развитии.\n",
        "- series B funding. Это четвертый этап, на котором инвесторы проверяют, продолжает ли компания расти, чтобы они могли получить долгосрочную прибыль.\n",
        "- series C funding, на этом этапе ожидается, что компания, добившаяся успеха на ранней стадии, будет иметь большой входящий доход.\n",
        "- series D funding, здесь компания может выбрать переход в серию D или на стадию IPO (первичное публичное размещение акций). Переход к этому этапу вместо этапа IPO не является признаком неудачи.\n",
        "- Стадия IPO — это когда компания перешла в публичную компанию, на которой компания выпускает новые акции для широкой публики, которая теперь может покупать акции бизнеса.\n",
        "\n",
        "Каждая компания может перейти в следующий раунд только в том случае, если ей удастся завершить текущий раунд, то есть если они собрали достаточно капитала.\n",
        "\n",
        "Интересная статистика от: https://explodingtopics.com/blog/startup-failure-stats <q>According to the latest data, up to 90% of startups fail. Across almost all industries, the average failure rate for year one is 10%. However, in years two through five, a staggering 70% of new businesses will fail.</q>\n",
        "То ест грубо говорят большинство новых стартапов не выживают более пять лет.\n",
        "\n",
        "Согласно с https://www.investopedia.com/articles/personal-finance/040915/how-many-startups-fail-and-why.asp , причинами сбоев стратапа являются:\n",
        "- У стартапа закончились деньги.\n",
        "- Целевой рынок неверен.\n",
        "- проведено недостаточно исследований.\n",
        "- Установлено плохое партнерство\n",
        "- Маркетинг был проведен неправильно\n",
        "- Предприниматель – новичок в своем деле."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSw8BlB0TZ0X"
      },
      "source": [
        "## Цель исследования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLfoUHzEJhoz"
      },
      "source": [
        "Поскольку речь идет о больших деньгах, наша цель — с помощью модели машинного обучения предсказать, закроется ли стартап."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wz1TK41oTWAA"
      },
      "source": [
        "## Ход исследования"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkuNLrQhXBp9"
      },
      "source": [
        "- Подгатовка данных: Загрузка и изучение общей информации из предоставлено датасета.\n",
        "- Предоработка данных: Обработка пропущенных значений, корректировка типа данных, дубликатов и других аномалий.\n",
        "- Исследовательский анализ данных: Изучение основных параметров объектов, их распределение, присутствие выбросов,  явление и обработка аномали\n",
        "- Анализ корреляции: Исследование связи между признаками чтобы понимать если нужно или нет устранить несколко признаких\n",
        "- Построение пайплайн с методом оптимизации чтобы отобрать самую лучшую модель для МО\n",
        "- Анализы важности признаков чтобы понимать какие признаки важны и какие нет\n",
        "- Попытка увеличть качество модели при помощи устранения не важных призаков\n",
        "- Изучение пределов модели и если она соответствует ожиданиям закачика\n",
        "- Используйте нашу лучшую модель с тестовым набором данных, чтобы предсказать, закроются ли стартапы из датасета\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41OTitSd8w5u",
        "outputId": "5a71e7e4-264b-4073-d7a9-0edf0ad854fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.1)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.1.4)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: seaborn\n",
            "  Attempting uninstall: seaborn\n",
            "    Found existing installation: seaborn 0.13.1\n",
            "    Uninstalling seaborn-0.13.1:\n",
            "      Successfully uninstalled seaborn-0.13.1\n",
            "Successfully installed seaborn-0.13.2\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.3.2\n",
            "    Uninstalling scikit-learn-1.3.2:\n",
            "      Successfully uninstalled scikit-learn-1.3.2\n",
            "Successfully installed scikit-learn-1.5.1\n",
            "Collecting phik\n",
            "  Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from phik) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5.2 in /usr/local/lib/python3.10/dist-packages (from phik) (1.13.1)\n",
            "Requirement already satisfied: pandas>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from phik) (2.1.4)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.10/dist-packages (from phik) (3.7.1)\n",
            "Requirement already satisfied: joblib>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from phik) (1.4.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.2.3->phik) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.1->phik) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.1->phik) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.2.3->phik) (1.16.0)\n",
            "Downloading phik-0.12.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (686 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.1/686.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: phik\n",
            "Successfully installed phik-0.12.4\n",
            "Collecting shap\n",
            "  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.1.4)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n",
            "Collecting slicer==0.0.8 (from shap)\n",
            "  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n",
            "Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.46.0 slicer-0.0.8\n",
            "Collecting category_encoders\n",
            "  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.5.1)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.2)\n",
            "Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.1.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n",
            "Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: category_encoders\n",
            "Successfully installed category_encoders-2.6.3\n",
            "Collecting catboost\n",
            "  Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.13.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.15.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2024.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (9.0.0)\n",
            "Downloading catboost-1.2.5-cp310-cp310-manylinux2014_x86_64.whl (98.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: catboost\n"
          ]
        }
      ],
      "source": [
        "# Библиотеки\n",
        "\n",
        "!pip install -U seaborn\n",
        "!pip install -U scikit-learn\n",
        "!pip install phik\n",
        "!pip install shap\n",
        "!pip install category_encoders\n",
        "!pip install catboost\n",
        "!pip3 install pycaret\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import phik\n",
        "import shap\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "# загружаем модуль SelectKBest\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "# загружаем модуль пермутации\n",
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Encoders\n",
        "import category_encoders as ce\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "# загружаем класс pipeline\n",
        "#from sklearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import Pipeline\n",
        "\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from imblearn.combine import SMOTETomek\n",
        "from imblearn.ensemble import BalancedRandomForestClassifier\n",
        "\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder\n",
        "\n",
        "# загружаем функцию для работы с метриками\n",
        "from sklearn.metrics import f1_score, make_scorer\n",
        "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "# импортируем itertools\n",
        "from itertools import combinations\n",
        "\n",
        "from pycaret import classification\n",
        "# from pycaret.utils import enable_colab\n",
        "# enable_colab()\n",
        "\n",
        "shap.initjs()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N73M5rH8w54"
      },
      "source": [
        "# Загрузка данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yYMVAlC8w58"
      },
      "source": [
        "## Тренировочние данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWxwbGz88w59"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Startups_project/kaggle_startups_train_28062024.csv')\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gat82h9S8w6A"
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvQGnqs18w6D"
      },
      "source": [
        "Датафрейм с тренировочнами датами содержит 52516 строки и 13 столбцов, 1 столбцец с количественными данными:\n",
        "\n",
        "- funding_total_usd, общая сумма финансирования в USD;\n",
        "\n",
        "и 12 столбцов с категориальными данными:\n",
        "- name - Название стартапа\n",
        "- category_list - Список категорий, к которым относится стартап\n",
        "- status - Статус стартапа (закрыт или действующий)\n",
        "- country_code - Код страны\n",
        "- state_code - Код штата\n",
        "- region - Регион\n",
        "- city - Город\n",
        "- funding_rounds - Количество раундов финансирования\n",
        "- founded_at - Дата основания\n",
        "- first_funding_at - Дата первого раунда финансирования\n",
        "- last_funding_at - Дата последнего раунда финансирования\n",
        "- closed_at - Дата закрытия стартапа (если применимо)\n",
        "\n",
        "Отметим что ect 1 пропуск в столбце 'name' и многих пропусков в столбце 'category_list', 'funding_total_usd', 'country_code', 'state_code', 'region', 'city' и 'closed_at'.\n",
        "\n",
        "Отметим что 'name', 'category_list', 'funding_total_usd', 'status', 'country_code', 'state_code', 'region', 'city', 'funding_rounds' в корректном тип дата.\n",
        "Однако 'founded_at', 'first_funding_at', 'last_funding_at', 'closed_at' нужно их конвертировать в pandas datetime.\n",
        "\n",
        "'status' - целевой признак. Наше машиное обученое модели являеться классификационны из-за того что целевой признак - категоряльное. Можно тоже думать что деревяний модел будет хорошо работать потому что у нас болшинство категоряльние признаки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tuGDuIj8w6G"
      },
      "source": [
        "## Тестовочное данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dTVluWa58w6H"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Startups_project/kaggle_startups_test_28062024.csv')\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hvzgi3SB8w6L"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8yldC8xw8w6Q"
      },
      "source": [
        "По сравню с тренировочной датафреймом, в датафрейме df_test убрали столбце 'status', 'closed_at' и 'founded_at', и появились новий столбце - 'lifetime' (количествие значение). Датафрейм содержит 13125 строки и мы видим  что у нас пропуски в 6 столбцах : 'category_list', 'funding_total_round', 'country_code', 'state_code', 'region' и 'city'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6g8GN60v8w6S"
      },
      "source": [
        "## Датафрейм с целевым признаком"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1Z7grAc8w6U"
      },
      "outputs": [],
      "source": [
        "y_test = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Startups_project/kaggle_startups_sample_submit_28062024.csv')\n",
        "y_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGzElY-_8w6X"
      },
      "outputs": [],
      "source": [
        "y_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2Vzl96u8w6Y"
      },
      "source": [
        "Это датафрейм - наш целевой признак, у него одно и то же индексы как у df_test и они в том же порядке.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oo3z7n48w6Z"
      },
      "source": [
        "# Преоработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlsSOeYs8w6a"
      },
      "source": [
        "## Преобразование типа данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC47Gr_X8w6b"
      },
      "outputs": [],
      "source": [
        "dataframes = [df_train, df_test]\n",
        "columns = ['founded_at', 'first_funding_at', 'last_funding_at', 'closed_at']\n",
        "\n",
        "for df in dataframes:\n",
        "    for col in columns:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_datetime(df[col], format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2N6hbv78w6c"
      },
      "outputs": [],
      "source": [
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaSGkeG28w6d"
      },
      "outputs": [],
      "source": [
        "df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmGW-6pF8w6f"
      },
      "source": [
        "Преобразования выполнены успешно."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi-dybEW8w6g"
      },
      "source": [
        "## Пропуски в датасетах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-3BVK-G8w6h"
      },
      "outputs": [],
      "source": [
        "df_train.isna().sum()/len(df_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xdFtSp78w6j"
      },
      "source": [
        "Не хватает один имя которое наверно не будем заменить так как мы убираем этот столбец во вермя моделировании. Пропуски в:\n",
        "- category_list составляет 4,69% данных,\n",
        "- funding_total_usd составляет 19,17% данных,\n",
        "- country_code составляет 10,48% данных,\n",
        "- state_code составляет 12,88% данных,\n",
        "- region составляет 12,11% данных,\n",
        "- city составляет 12,11% данных,\n",
        "- closed_at составляет 90,64% данных\n",
        "\n",
        "\n",
        "Мы будем заниматься пропуски в столбце 'category_list', 'funding_total_usd', 'country_code', 'state_code', 'region', 'city' во время pipeline с inputer методом.\n",
        "Пропуски в столбце 'closed_at' будем заниматься в часть 'feature engineering' чтобы создать столбец 'lifetime'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0sLBfhN8w6j"
      },
      "source": [
        "Давайте посмотрим на пропуски. Мы можем найти некоторые категории с названием компании. Однако что касается отсутствующих стран, мы не можем на самом деле восполнить это, только если сможем угадать их по городам или регионам, если они существовают."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UhK314qo8w6n"
      },
      "outputs": [],
      "source": [
        "df_train.query('country_code.isna()==True and state_code.isna()==False or country_code.isna()==True and city.isna()==False '\\\n",
        "              'or country_code.isna()==True and region.isna()==False')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY8bWEbjf1yw"
      },
      "source": [
        "Мы видим, что когда название страны отсутствует, нет соответствующего города или региона."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PQURp--e8w6o"
      },
      "outputs": [],
      "source": [
        "df_train['country_code'].value_counts(normalize=True)[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cquqn91SgamR"
      },
      "source": [
        "Вероятно, мы будем использовать стратегию «most frequent» с SimpleImputer для признака «country_code»."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66f42yhA8w6q"
      },
      "outputs": [],
      "source": [
        "df_train['state_code'].value_counts(normalize=True)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy9Lskxg8w6q"
      },
      "outputs": [],
      "source": [
        "df_train['region'].value_counts(normalize=True)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "migAhjF28w6s"
      },
      "outputs": [],
      "source": [
        "df_train['city'].value_counts(normalize=True)[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U621IgywJoHc"
      },
      "outputs": [],
      "source": [
        "df_test.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymWAmWpl8w6t"
      },
      "source": [
        "Если страна отсутствует, невозможно угадать, что это такое по другим признаками «state_code», «region» или «city», поскольку они также отсутствуют, когда отсутствует код страны. Если мы посмотрим на 10 наиболее представленных стран, мы увидим, что США представляют 63,2% данных, вторая Великобритания представляет только 6,2%, третья, Канада, представляет 3,2% и десятая, Нидерланды, представляет менее 1%. . Вероятно, стоит использовать опцию 'most_frequent' с SimpleImputer для «country_code». Однако было бы сложнее использовать эту функцию для «state_code», «region» и «city», поскольку наиболее представленные городы, регионы и штаты представляют соответственно только 6% (San Francisco), 15% (San Francisco Bay Area) и 22% (California). Использование стратегии 'most frequent' для этих признаков можеть приведет к искажению набора данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vRnLQl4z8w6k"
      },
      "outputs": [],
      "source": [
        "df_train['category_list'].value_counts(normalize=True)[:15]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kOMA1W88w6m"
      },
      "source": [
        "Что касается признак категории, нам, вероятно, нужно поработать над этой функцией, прежде чем мы сможем узнать, какую стратегию использовать с SimpleImputer. Например, мы видим категории, которые, возможно, придется сгруппировать, например:\n",
        "'Hardware + Software' и 'Enterprise Software'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY9cR5kH8w6v"
      },
      "source": [
        "Что касается пропущенных числовых значений в 'fund_total_usd', мы собираемся использовать KNNImputer для замены пропущенных значений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "862ZhIwC8w6w"
      },
      "source": [
        "## Дупликаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPOMPlT38w6x"
      },
      "source": [
        "### Явние дупликаты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWRveCBY8w6y"
      },
      "outputs": [],
      "source": [
        "def find_obvious_duplicates(dataframe):\n",
        "    return dataframe.duplicated().sum()\n",
        "\n",
        "dataframes = [df_train]\n",
        "dataframes_names = ['df_train']\n",
        "\n",
        "for index, dataframe in enumerate(dataframes):\n",
        "    res = find_obvious_duplicates(dataframe)\n",
        "    print(f'{res} явны дупликаты в датафрейме {dataframes_names[index]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdIP2HVk8w60"
      },
      "source": [
        "Нет явных дупликатов."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmWE-2TF8w60"
      },
      "source": [
        "### Проверка уникальнте значение в столбце 'name'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsOMToEa8w61"
      },
      "outputs": [],
      "source": [
        "def check_duplicates_id(dataframe):\n",
        "    return dataframe.duplicated(subset='name').sum()\n",
        "\n",
        "dataframes = [df_train]\n",
        "dataframes_names = ['df_train', 'df_test']\n",
        "\n",
        "for index, dataframe in enumerate(dataframes):\n",
        "    res = check_duplicates_id(dataframe)\n",
        "    print(f'{res} дупликаты в столбце \\'name\\' в датафрейме {dataframes_names[index]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnRrHhCR8w63"
      },
      "source": [
        "Все стартапы точно уникальние."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eG-NurmJkwe_"
      },
      "outputs": [],
      "source": [
        "set(df_train['name'].to_list()).intersection(df_test['name'].to_list())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYqn-nORlP5e"
      },
      "source": [
        "Эти два набора данных не связаны ни с одной компанией."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGOvLIfQ8w64"
      },
      "source": [
        "### Проверка присутствия не явных дупликатов в других столбцах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3WeegAZv8w65"
      },
      "outputs": [],
      "source": [
        "# Список категориальных столбцов\n",
        "col_cat = ['category_list', 'status', 'country_code', 'state_code', 'region', 'city']\n",
        "\n",
        "#  Создаем пустой лист для соханиение резултат\n",
        "list_unique = []\n",
        "\n",
        "list_unique_cat = {}\n",
        "\n",
        "for col in col_cat:\n",
        "    if col in df_train.columns:\n",
        "        list_unique_cat[col] = df_train[col].unique().tolist()\n",
        "list_unique.append(list_unique_cat)\n",
        "list_unique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0e3j3dq8w66"
      },
      "source": [
        "Похоже, что большая часть значений уникальна, нет дубликатов, за исключением категорий, где есть некоторые слова, написанные иногда с «s», а иногда без ('Application' и 'Applications').\n",
        "Мы уже понимаем, что столбцы содержают много разных значений, что заставит нас выбрать правильный кодировщик, чтобы избежать проклятия размерности (dimensionnality curse), и правильную стратегию, чтобы наша модель не переобучалось."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPBgeDGj8w67"
      },
      "source": [
        "## Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4fREA418w68"
      },
      "source": [
        "Поскольку мы собираемся добавить столбцы в наши фреймы данных df_train и df_test, давайте сделаем их копию, чтобы сохранить исходную нетронутой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5O1m1W08w69"
      },
      "outputs": [],
      "source": [
        "# Копируем датафрейм df_train\n",
        "X_train = df_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6St7s8F8w6-"
      },
      "outputs": [],
      "source": [
        "# Копируем датафрейм df_test\n",
        "X_test = df_test.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cKXhtNX8w6_"
      },
      "source": [
        "## Создание столбец first_funding_year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kgC8kzJnXTH"
      },
      "source": [
        "Поскольку мы не можем закодировать объект datetime, нам нужно извлечь важную информацию из нашей даты. Год может быть важным. Например, в 2008 году случился экономический кризис, и это могло повлиять на данные."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghyYrdVt8w7A"
      },
      "outputs": [],
      "source": [
        "X_train['first_funding_year'] = X_train['first_funding_at'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rh_bIKKg8w7C"
      },
      "outputs": [],
      "source": [
        "X_test['first_funding_year'] = X_test['first_funding_at'].dt.year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywTCFWnE8w7D"
      },
      "source": [
        "## Создание столбец last_funding_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nF9cU7wc8w7E"
      },
      "outputs": [],
      "source": [
        "X_train['last_funding_year'] = X_train['last_funding_at'].dt.year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elmR7q5a8w7F"
      },
      "outputs": [],
      "source": [
        "X_test['last_funding_year'] = X_test['last_funding_at'].dt.year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef6tgzJ7o-fn"
      },
      "source": [
        "## Создание столбец first_funding_month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWiEusR2pe0s"
      },
      "source": [
        "Месяц также может иметь значение. Мы знаем, что люди делают ремонт в доме обычно летом, во время Рождества, людям приходится тратить больше и т. д. Вероятно, это не имеет значения в масштабах компании, но мы все равно можем попробовать, в конце мы всегда сможем удалить это, оснобено, если это усложняло нашу модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2Tswu2XpdSM"
      },
      "outputs": [],
      "source": [
        "X_train['first_funding_month'] = X_train['first_funding_at'].dt.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-6BGw0Eko8yY"
      },
      "outputs": [],
      "source": [
        "X_test['first_funding_month'] = X_test['first_funding_at'].dt.month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH22Ls2UrkOP"
      },
      "source": [
        "## Создание столбец last_funding_month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjcKaTharqAk"
      },
      "outputs": [],
      "source": [
        "X_train['last_funding_month'] = X_train['last_funding_at'].dt.month"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9XH477crqUk"
      },
      "outputs": [],
      "source": [
        "X_test['last_funding_month'] = X_test['last_funding_at'].dt.month"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBvVbQjC8w7F"
      },
      "source": [
        "## Создание столбец 'lifetime'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKXsdPzr8w7G"
      },
      "source": [
        "Так как у нас нет столбец 'closed_at' и 'found_at' в X_test и нет столбца 'lifetime' в X_train. Я решил создать столбце 'lifetime' в X_train. Во время моделирование мы будем убирать столбец 'closed_at' из датасета. Дата загрузки - известный, это 2018-01-01, значить что мы можем рачитывать значение столбца 'lifetime'.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jA3NoJJ8w7H"
      },
      "outputs": [],
      "source": [
        "len(X_train.query('status == \"operating\"'))/len(X_train) == X_train['closed_at'].isna().sum()/len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icKVceVc8w7I"
      },
      "source": [
        "Пропуски в столбце 'closed_at' - компани которие ещё работают.\n",
        "\n",
        "Во первых, нам нужно создать новый столбец от столбца 'closed_at' где пропуски будут замененые с значение дата загрузки - '2018-01-01'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1NBnkhmM8w7K"
      },
      "outputs": [],
      "source": [
        "# Преобразоваем строк '2018-01-01' на datetime\n",
        "loading_date = pd.to_datetime('2018-01-01')\n",
        "\n",
        "# Заменяем пропуски из 'closed_at' с датой загрузки\n",
        "X_train['closed_at'] = X_train['closed_at'].fillna(loading_date)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skMpICNA8w7L"
      },
      "outputs": [],
      "source": [
        "# Расчитываем значение столбца 'lifetime'\n",
        "X_train['lifetime'] = X_train['closed_at']-X_train['founded_at']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id82l7WW8w7M"
      },
      "outputs": [],
      "source": [
        "# Пробразоваем значение от день до integer\n",
        "X_train['lifetime'] = X_train['lifetime'].dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92w4n5Am8w7N"
      },
      "outputs": [],
      "source": [
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfoNf_HCOnCO"
      },
      "source": [
        "## Создание столбец pre_seed_last_round"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaiubwRxQZQs"
      },
      "source": [
        "Поскольку год и месяц будут категориялным признаком, у нас нет представления о том, как долго финансирование было. Конечно, разница между первым и последним финансированием не говорит нам, как долго длился последний раунд и длится ли он еще. Помимо этого процента, мы получаем представление о том, как долго длилось время перед первым раудом, что очень важно для стартапа. Кто-то может утверждать, что чем дольше компания будет более успешной, но это гипотеза."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PapVmRXPP0b"
      },
      "source": [
        "Проверим, что 'lifetime' никогда не бывает равно нулю."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXKwdDTvPUWg"
      },
      "outputs": [],
      "source": [
        "len(X_train[X_train['lifetime']==0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB0NTokcQLzW"
      },
      "source": [
        "Lifetime никогда не бывает равно 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1nQ73cm8OxpP"
      },
      "outputs": [],
      "source": [
        "X_train['pre_seed_last_round'] = 1 - (X_train['last_funding_at']-X_train['first_funding_at']).dt.days/X_train['lifetime']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrDOUTehP7v4"
      },
      "outputs": [],
      "source": [
        "X_test['pre_seed_last_round'] = 1 - (X_test['last_funding_at']-X_test['first_funding_at']).dt.days/X_train['lifetime']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnTAwROF8w72"
      },
      "source": [
        "## Создание столбец countries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXOY7Zu58w73"
      },
      "source": [
        "Одной из проблем с таким большим количеством отдельных значений будет переобучение: попытка модели соответствовать шуму, категориям с низкой частотой данных. Кроме того, есть еще одна проблема: новые значения из теста не попали в обучающую выборку. Вот почему я собираюсь сгруппировать низкочастотные значения вместе для набора обучающих и тестовых данных, для столбцов 'country_zone' и для других категориальных признаков ('state_code', 'region', 'city') в следующих частях.\n",
        "\n",
        "Сгруппируем страны с частотой менее 20 вместе в группу 'Misc' ('Miscellaneous')."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSOVHXZ78w75"
      },
      "outputs": [],
      "source": [
        "n_threshold = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMsA6p6L8w75"
      },
      "outputs": [],
      "source": [
        "# Подсчет количества одиночных значений в столбце категорий\n",
        "countries_counts = X_train['country_code'].value_counts()\n",
        "# Получите индексы объекта из категорий объектов, который отображается меньше порогового числа\n",
        "countries_count_index = X_train[X_train['country_code'].map(countries_counts)<=n_threshold].index.to_list()\n",
        "# Нам нужно скопировать 'country_code' в столбец 'countries'\n",
        "X_train['countries'] = X_train['country_code']\n",
        "# Замена значения значений, которое меньше порогового числа, на значение 'Misc.'\n",
        "X_train.loc[countries_count_index, 'countries'] = 'Misc.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs9V4fWa8w77"
      },
      "outputs": [],
      "source": [
        "# Подсчет количества одиночных значений в столбце категорий\n",
        "countries_counts_test = X_test['country_code'].value_counts()\n",
        "# Получите индексы объекта из категорий объектов, который отображается меньше порогового числа\n",
        "countries_count_index_test = X_test[X_test['country_code'].map(countries_counts_test)<=n_threshold].index.to_list()\n",
        "# Нам нужно скопировать 'country_code' в столбец 'countries'\n",
        "X_test['countries'] = X_test['country_code']\n",
        "# Замена значения значений, которое меньше порогового числа, на значение 'Misc.'\n",
        "X_test.loc[countries_count_index_test, 'countries'] = 'Misc.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvvuz9Lm24Wg"
      },
      "source": [
        "Мы собираемся сделать то же самое для 'state_code', 'region', 'city'."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAr5iKSs8w78"
      },
      "source": [
        "## Создание столбец states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDCHBZOs8w79"
      },
      "outputs": [],
      "source": [
        "states_counts = X_train['state_code'].value_counts()\n",
        "\n",
        "states_count_index = X_train[X_train['state_code'].map(states_counts)<=n_threshold].index.to_list()\n",
        "\n",
        "X_train['states'] = X_train['state_code']\n",
        "\n",
        "X_train.loc[states_count_index, 'states'] = 'misc.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNguxi_L8w7-"
      },
      "outputs": [],
      "source": [
        "states_counts_test = X_test['state_code'].value_counts()\n",
        "\n",
        "states_count_index_test = X_test[X_test['state_code'].map(states_counts_test)<=n_threshold].index.to_list()\n",
        "\n",
        "X_test['states'] = X_test['state_code']\n",
        "\n",
        "X_test.loc[states_count_index_test, 'states'] = 'misc.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSwAHdJh8w7_"
      },
      "source": [
        "## Создание столбец regions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1H9Yj-E8w8A"
      },
      "outputs": [],
      "source": [
        "regions_counts = X_train['region'].value_counts()\n",
        "\n",
        "regions_count_index = X_train[X_train['region'].map(regions_counts)<=n_threshold].index.to_list()\n",
        "\n",
        "X_train['regions'] = X_train['region']\n",
        "\n",
        "X_train.loc[regions_count_index, 'regions'] = 'misc.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm2ZfYDh8w8A"
      },
      "outputs": [],
      "source": [
        "regions_counts_test = X_test['region'].value_counts()\n",
        "\n",
        "regions_count_index_test = X_test[X_test['region'].map(regions_counts_test)<=n_threshold].index.to_list()\n",
        "\n",
        "X_test['regions'] = X_test['region']\n",
        "\n",
        "X_test.loc[regions_count_index_test, 'regions'] = 'misc.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KrmFDoc8w8B"
      },
      "source": [
        "## Создание столбец cities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jqYRCEhP8w8C"
      },
      "outputs": [],
      "source": [
        "cities_counts = X_train['city'].value_counts()#(dropna=False)\n",
        "\n",
        "cities_count_index = X_train[X_train['city'].map(cities_counts)<=n_threshold].index.to_list()\n",
        "\n",
        "X_train['cities'] = X_train['city']\n",
        "\n",
        "X_train.loc[cities_count_index, 'cities'] = 'misc.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuyWqf968w8D"
      },
      "outputs": [],
      "source": [
        "cities_counts_test = X_test['city'].value_counts()\n",
        "\n",
        "cities_count_index_test = X_test[X_test['city'].map(cities_counts_test)<=n_threshold].index.to_list()\n",
        "\n",
        "X_test['cities'] = X_test['city']\n",
        "\n",
        "X_test.loc[cities_count_index_test, 'cities'] = 'misc.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lCrkdQD8w8D"
      },
      "source": [
        "## Создание столбец sub_categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj-YxqH38w8E"
      },
      "source": [
        "Одна из основных проблем с нашим датафреймом заключается в том, что у нас слишком много уникальных значений, и это может стать проблемой во время кодирования обучение модели. Попробуем уменьшить количество уникальных значений для столбца 'category_list'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3EctnDe8w8E"
      },
      "outputs": [],
      "source": [
        "len(X_train['category_list'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2a-4_PR8w8G"
      },
      "source": [
        "22105 разние категории, это очень много. Давайте групируем несколкие стартары по главнам категорями с помощю словаром."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fTCeVibv8w8G"
      },
      "outputs": [],
      "source": [
        "cat_dict={\n",
        "'Biotechnology':['Biotechnology', 'Medical Devices', 'Health Diagnostics', 'Life Sciences', 'Diagnostics'],\n",
        "'Hardware, Software & Apps': ['Software', 'Enterprise Software', 'Apps', 'Open Source', \\\n",
        "                                'Website and Application Development', 'Web Development', \\\n",
        "                                'Hardware + Software', 'Productivity Software', 'Android', \\\n",
        "                                'Developer APIs', 'Algorithms', 'Hardware', 'iPhone', 'Developer Tools',\\\n",
        "                                'Communications Hardware', 'Browser Extensions', 'iPad', 'iOS',\\\n",
        "                                'Real Time', 'Gamification', 'Application', 'Applications', 'Web'],\n",
        "'Internet, E-Commerce & Mobile':['Bitcoin', 'E-Commerce', 'Content', 'M-', 'Social Media', \\\n",
        "                                  'Curated Web', 'Internet', 'Online', 'Messaging', 'Search', \\\n",
        "                                  'Marketplaces', 'Wireless', 'Networks', 'Bluetooth', 'Networking', \\\n",
        "                                  'Telecommunications', 'VoIP', 'Development Platforms', \\\n",
        "                                  'Internet of Things', 'Market Research', 'Online Shopping', \\\n",
        "                                  'Online Travel', 'Payments', 'Mobile Payments', 'Mobile', \\\n",
        "                                  'Advertising', 'Consumer Internet', 'Email', 'Social Commerce', \\\n",
        "                                  'Chat', 'All Students', 'Coupons', 'Content Delivery', \\\n",
        "                                  'App Marketing', 'Internet Marketing', 'Social Network Media', 'Gps', \\\n",
        "                                 'Online Dating', 'Service Providers', 'E-Commerce Platforms', \\\n",
        "                                  'Content Discovery', 'Ediscovery', 'App Stores', 'Advertising Networks', \\\n",
        "                                  'Email Marketing', 'Comparison Shopping', 'Online Reservations',\\\n",
        "                                 'Maps', 'Mobile Advertising', 'Online Scheduling', 'Mobile', \\\n",
        "                                  'Bridging Online and Offline', 'Digital Media'],\n",
        "'Energy':['Energy', 'Oil & Gas', 'Oil', 'Gas'],\n",
        "'Clean Technology':['Clean Technology', 'Green', 'Environmental Innovation', 'Renewable Energies', 'Solar',\n",
        "                   'Clean Energy'],\n",
        "'Health care':['Health Care', 'Healthcare', 'Health', 'Care', 'Health Wellness', 'Medical', 'Hospitals', \\\n",
        "               'Fitness', 'Cannabis', 'Sports', 'Clinical Trials', 'Dental', 'Doctors', 'Exercise',\\\n",
        "               'Medicine', 'Doctor'],\n",
        "'Entertainment':['Games', 'Game', 'Events', 'Video Games', 'Art', 'Virtual Worlds', 'Video Streaming ', \\\n",
        "                 'Music', 'Augmented Reality', 'Film', 'Concerts', 'Leisure', 'Artists Globally', \\\n",
        "                 'Creative', 'Entertainment Industry', 'Fantasy Sports', 'Angels', 'Celebrity', 'Event', \\\n",
        "                'Online Gaming', 'Comics', 'Entertainement', 'Entertainment', 'Video', 'Audio', \\\n",
        "                 'Nightlife', 'Weddings'],\n",
        "'Education':['EdTech', 'Education', 'Colleges', 'Universities', 'Educational Games', 'College Campuses',\\\n",
        "            'School'],\n",
        "'Business & Professional Services':['Finance', 'Consulting', 'Advertising', 'Public Relations', \\\n",
        "                                    'Venture Capital', 'Legal','Local Businesses', 'Startups', \\\n",
        "                                    'Business Services', 'Alumni', 'Enterprises', 'Recruiting', \\\n",
        "                                     'Banking', 'Investment Management', 'Crowdfunding', 'Trading', \\\n",
        "                                    'Outsourcing', 'Small and Medium Businesses', 'Staffing Firms', 'B2B',\\\n",
        "                                    'Business Productivity', 'Advice', 'Logistics', 'Credits', 'Discount',\\\n",
        "                                    'Document Management', 'Reviews and Recommendations', 'Crowdsourcing',\\\n",
        "                                    'Sales and Marketing', 'Freelancers', 'Employer Benefits Programs', \\\n",
        "                                    'Risk Management', 'Business', 'Entrepreneur', 'Collaboration',\\\n",
        "                                    'Accounting', 'Designers', 'Surveys', 'Incubators', 'Distributors',\\\n",
        "                                   'Ad Targeting', 'Billing', 'Employment', 'Contact Management', 'CRM', \\\n",
        "                                    'Marketing', 'Human Resources', 'Career', 'Law',\\\n",
        "                                    'Financial technology', 'FinTech'],\n",
        "'Governement & Public Services':['Defense', 'Public Transportation', 'Governement', 'Governments',\\\n",
        "                                 'Aerospace', 'Geosptatial', 'Politics'],\n",
        "'Data Storage & Management':['Big Data', 'Cloud Computing and Storage', 'Data Analytics', 'Data Centers', \\\n",
        "                             'Web Hosting', 'Data Security', 'SaaS', 'Storage', 'Cloud Computing',\\\n",
        "                             'Cloud Data Services', 'Cyber Security', 'Network Security', \\\n",
        "                             'Big Data Analytics', 'Classifiels', 'File Sharing', 'Data Visualization',\\\n",
        "                             'Cloud Management', 'Data Mining', 'Machine Learning', 'Photo Sharing', 'P2P',\\\n",
        "                             'Databases', 'Data', 'Analytics','Security', 'Peer-to-Peer', 'Cloud Security'],\n",
        "'Consumers & Goods services':['Clothing', 'Fashion', 'Financial Services', 'Photography', \\\n",
        "                                       'Services', 'Consumer Electronics', 'Consumer Goods', 'Consumers',\\\n",
        "                                       'Beauty', 'Home Automation', 'Cars', 'Cosmetics', 'Construction', \\\n",
        "                                       'Location Based Services', 'Utilities', 'Real Estate', 'Home',\\\n",
        "                                       'Collectibles', 'Rental Housing', 'Home Decor', 'Printing', \\\n",
        "                                       'Collaborative Consumption','Auctions', 'Rental',\\\n",
        "                                       'Distribution', 'Commercial Real Estate', 'Transportation', \\\n",
        "                                       'Delivery', 'Pets', 'Babies', 'Carreer Planning', \\\n",
        "                                       'Property Management', 'Electrical Distribution', \\\n",
        "                                       'Lifestyle', 'Consumer Lending', 'Coffee', 'Cooking', 'Goods',\\\n",
        "                                       'Local', 'Health and Insurance', 'Wearable',\\\n",
        "                                       'Bicycles', 'Insurance', 'Kids', 'Domains', 'Baby Accessories',\\\n",
        "                                       'Customer Service', 'Retail', 'Shopping', 'Toys', 'Jewelry', \\\n",
        "                                       'Realtors', 'Lingerie', 'Furniture', 'Spas', 'Women', 'Parking',\\\n",
        "                                      'Service'],\n",
        "'Chemicals and Materials':['Advanced Materials', 'Chemicals', 'Minerals', 'Pesticides', 'Composites', \\\n",
        "                           'Textiles', 'Materials'],\n",
        "'Hospitality':['Hospitality', 'Restaurants', 'Reservation', 'Hostels', 'Hotels', 'Travel & Tourism', \\\n",
        "               'Travel', 'Adventure Travel','Tourism'],\n",
        "'Technology and Industry':['Technologies', 'Technology', 'Tech', 'TECH', 'Nanotechnology', 'Design',\n",
        "                           'Information Technology', 'Electronics', 'Computers', 'Semiconductors', \\\n",
        "                           '3D Printing', 'Automotive', 'Robotics', \\\n",
        "                           'Communications Infrastructure', 'Industrial Automation', '3D Technology', '3D', \\\n",
        "                           'Architecture', 'Manufacturing', 'Engineering', 'Biometrics', 'Drones', 'Auto',\\\n",
        "                           'Batteries', 'Innovation Engineering', 'Assisitive Technology', \\\n",
        "                           'Engineering Firms', 'Digital Signage', 'Bioinformatics', 'Mining Technologies',\\\n",
        "                           'Boating Industry', 'Infrastructure', 'Industrial', 'IT', 'Vision', \\\n",
        "                           'Artificial Intelligence', 'Vehicles', 'Engineers'],\n",
        "'Media':['Media', 'News', 'Broadcasting', 'Television', 'Publishing',  'Journalism'],\n",
        "'Pharma':['Pharmaceuticals', 'Bio-Pharm', 'Therapeutics', 'Drugs'],\n",
        "'Social':['Nonprofits', 'Non profits', 'Non Profit', 'Communities', 'Charity'],\n",
        "'Food':['Food Processing', 'Specialty Foods', 'Wine And Spirits', 'Agriculture', 'Farming', \\\n",
        "        'Craft Beer', 'Brewing', 'Organic', 'Fruit'],\n",
        "'Misc.':['Misc.']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enkWmATI8w8H"
      },
      "outputs": [],
      "source": [
        "# Инвертируйем ключ и значения, чтобы создать новый словарь для сопоставления значений, извлеченных из столбца списка категорий.\n",
        "from collections import defaultdict\n",
        "inv_cat_list = defaultdict(str)\n",
        "\n",
        "for keys, vals in cat_dict.items():\n",
        "    for val in vals:\n",
        "        inv_cat_list[val]=keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HwLWgnYI8w8I"
      },
      "outputs": [],
      "source": [
        "# Создаем список ключей inv_cat_list\n",
        "cat_keys = list(inv_cat_list.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bI21Ap8y8w8L"
      },
      "outputs": [],
      "source": [
        "# Извлеките основные категории, появляющиеся в cat_keys\n",
        "def extract_main_cat(val):\n",
        "\n",
        "    if val in cat_keys: # Проверим, есть ли значение val в списке cat_keys.\n",
        "        return val\n",
        "    elif '|' in val: # категория с '|' внутри\n",
        "        if val.split('|')[0] in cat_keys:\n",
        "            return val.split('|')[0]\n",
        "        elif ' ' in val.split('|')[0]:\n",
        "            if val.split('|')[0].split(' ')[0] in cat_keys:\n",
        "                return val.split('|')[0].split(' ')[0]\n",
        "            elif val.split('|')[0][-1] in cat_keys:\n",
        "                return val.split('|')[0].split(' ')[-1]\n",
        "            else:\n",
        "                if val.split('|')[1] in cat_keys:\n",
        "                    return val.split('|')[1]\n",
        "                elif ' ' in val.split('|')[1]:\n",
        "                    if val.split('|')[1].split(' ')[0] in cat_keys:\n",
        "                        return val.split('|')[1].split(' ')[0]\n",
        "                    elif val.split('|')[0].split(' ')[-1] in cat_keys:\n",
        "                        return val.split('|')[0].split(' ')[-1]\n",
        "                    else:   # Мы знаем, что всегда второе слово часто принадлежит cat_keys\n",
        "                        return 'Misc.'\n",
        "    elif ' ' in val: # категория где именни разделение с пробелом ' '\n",
        "        if val.split(' ')[0] in cat_keys:\n",
        "            return val.split(' ')[0]\n",
        "        else:\n",
        "            if val.split(' ')[1] in cat_keys:\n",
        "                return val.split(' ')[1]\n",
        "            else:\n",
        "                return 'Misc.'\n",
        "    elif '&' in val: # категория где именни разделение с '&'\n",
        "        if val.split('&')[0] in cat_keys:\n",
        "            return val.split('&')[0]\n",
        "        else:\n",
        "            if val.split('&')[-1] in cat_keys:\n",
        "                return val.split('&')[-1]\n",
        "            else:\n",
        "                return 'Misc.'\n",
        "    elif 'and' in val:   # категория где именни разделение с 'and'\n",
        "        if val.split('and')[0] in cat_keys:\n",
        "            return val.split('and')[0]\n",
        "        else:\n",
        "            if val.split('and')[-1] in cat_keys:\n",
        "                return val.split('and')[-1]\n",
        "            else:\n",
        "                return 'Misc.'\n",
        "    else:\n",
        "        return 'Misc.'\n",
        "\n",
        "\n",
        "X_train['main_category'] = X_train.query('~category_list.isna()')['category_list'].apply(extract_main_cat)\n",
        "X_test['main_category'] = X_test.query('~category_list.isna()')['category_list'].apply(extract_main_cat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dc2NRULN8w8P"
      },
      "outputs": [],
      "source": [
        "# Создание подкатегорий нашего столбца\n",
        "X_train['subcategories'] = X_train['main_category'].map(inv_cat_list, na_action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XVcKP3KL8w8P"
      },
      "outputs": [],
      "source": [
        "X_train['subcategories'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iyIRGTMc8w8Q"
      },
      "outputs": [],
      "source": [
        "X_train[X_train['subcategories']=='Misc.']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ysbUvv28w8R"
      },
      "outputs": [],
      "source": [
        "X_test['subcategories'] = X_test['main_category'].map(inv_cat_list, na_action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yuI54XRo8w8S"
      },
      "outputs": [],
      "source": [
        "X_test['subcategories'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRAme6_dBRSF"
      },
      "source": [
        "## Удаление временного столбца"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJI4P9H_BOLi"
      },
      "outputs": [],
      "source": [
        "X_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8WqdNp-BYrJ"
      },
      "outputs": [],
      "source": [
        "X_train.drop(['main_category'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2mCIPwMCJzx"
      },
      "outputs": [],
      "source": [
        "X_test.drop(['main_category'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLw9wL2i8w8V"
      },
      "source": [
        "## Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DFy8LDpN7LX"
      },
      "source": [
        "Мы получили менее 5 % пропущенных значений в «category_list» и около 10 % в «country_code», «state_code», «region», «city». Эти пропущенные значения будут обработаны во время работы паплайны с помощью метода SimpleImputer.\n",
        "\n",
        "Мы также заметили значительное количество уникальных категориальных значений. Нам пришлось сгруппировать категории стартапов в несколько категорий, которые наиболее информативны. Тогда у нас была очень разная частота, и группировка иногда может вызывать вопросы: должны ли мы отделять категорию \"Apps\" от категории \"Software, Hardware, and Apps\"? Должны ли мы объединить категории \"Mobile\" с категорией \"Apps\" и почему бы не объединили категорию \"Hospitality\" с категорией \"Customers Goods And Services\" ? Однако я не думаю, что это будет иметь большое разницы на MO. В списке категорий мы также группировали категории, которые мы не могли поместить ни в одну группу, в категорию под названием \"Misc.\".\n",
        "\n",
        "Мы использовали тот же принцип для признако географического местоположения (country_zone, city и т. д.), те значеня которы редко появились, групировали в группу \"Misc.\". Мы будем исползовать эту групу во время исползованнии  SimpleImputer, с опцим \"constant\", потому что я не уверен, что стратегия \"most frequent\" всегда является хорошей, поскольку она может исказить данные. Например за исключением \"США\", у нас не так много доминирующих категорий в 'state_code', 'region', 'city'.\n",
        "\n",
        "Тоже создали дополнителный признак 'pre_seed_last_round'. С начало я хотел создать пизнак которы покажет время перед первым фундом потому что подкотовка стартапы является очень важно что бы предотвратить его неудачу. К сожалению нет признака 'found_at' в тестовом датасете, вот почему создали признак 'pre_seed_last_round', доля которая отрожаеть сколко временни занимались все раундов кроме последние, a другая доля время перед первом раундом + время последнего раунда.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW0xnfNu8w8W"
      },
      "source": [
        "# Исследовательский анализ данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swQBzObs8w8X"
      },
      "source": [
        "## Статистика датафреймы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22iWjNuf8w8Y"
      },
      "outputs": [],
      "source": [
        "stat_train = X_train.drop(['first_funding_year','last_funding_year', 'first_funding_month',\\\n",
        "                           'last_funding_month'], axis=1).select_dtypes(include='number').describe()\n",
        "stat_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2EfvTtz8w8Z"
      },
      "outputs": [],
      "source": [
        "stat_test = X_test.drop(['first_funding_year','last_funding_year', 'first_funding_month', \\\n",
        "                         'last_funding_month'], axis=1).select_dtypes(include='number').describe()\n",
        "stat_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3mL5_ye8w8a"
      },
      "source": [
        "Что касается общего объема финансирования, средние значения между трениворочном и тестовом датасетом аналогичны, однако стандартное отклонение почти в два раза болшее у тренировочной датасета.\n",
        "\n",
        "Среднее 'lifetime' между датасетами близко, и оно более значительно в треновочном датасете.\n",
        "\n",
        "Что касается раунда финансирования, то в среднем он составляет от 1 до 2 раундов, и это понятно, поскольку первый и второй раунды являются наиболее важными критическими и сложним проходить для стартапов. Большая часть сбоев стартапов происходит примерно в этом временни. Это и понятно, потому что на этом этапе стартап начнет понимать, сработает ли его бизнес-план, идеи, ответит ли рынок положительно или нет. Наборы тестовых и обучающих данных в этих столбцах близки.\n",
        "\n",
        "В среднем срок жизни стартапа составляет около 3097 дней, но мы видим, что у нас есть исключения, возможно, успешные компании, которые живут более 17000 дней."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fxd4n8c3lubi"
      },
      "source": [
        "### Выбросы в датасетах"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ku4-sUd8w8b"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15, 7.5))\n",
        "\n",
        "col_num = ['funding_total_usd', 'funding_rounds', 'lifetime']\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "columns_names = ['funding_total_usd', 'lifetime', ]\n",
        "\n",
        "sample_type = ['в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, column in enumerate(X_train[col_num].columns):\n",
        "    for j, dataframe in enumerate(dataframes):\n",
        "\n",
        "        sns.boxplot(data=dataframe, x=column, ax=axes[2*i+j])\n",
        "\n",
        "        axes[2*i+j].set_title(f'Ящик с усами {sample_type[j%2]}')\n",
        "\n",
        "#plt.title(f'Боксплоты');\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDM8Zsk1vDeJ"
      },
      "source": [
        "## Проверка дисбаланс для выбросов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_an6btD3x9CD"
      },
      "source": [
        "Можно подумать, что в выбросах могло бы быть гораздо меньше объектов класса 0 («закрытых»). Конечно, если компания просуществует долго или заработает много денег, это означает, что бизнес прибыльен и вряд ли закроется. В этом случае выбросы могут быть очень полезны для разделения обоих классов. Что касается дисбаланса, можем ли мы вообще подумать об использовании anomaly fraud detection алгоритм для нашей модели, если выбросы помогают дифференцировать оба класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7cxWZLbhte3"
      },
      "outputs": [],
      "source": [
        "y_test.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1lNAs-P2FWP"
      },
      "outputs": [],
      "source": [
        "columns = ['funding_total_usd', 'lifetime', 'funding_rounds']\n",
        "s = [('заработовали большее', 'долларов'), ('работали большее', 'дней'), ('проходили больщее','раунды')]\n",
        "\n",
        "# Индекс для закрыты стартапы в тестовом датасете\n",
        "index_closed_test = y_test.query('status==\"closed\"').index.to_list()\n",
        "\n",
        "for i,col in enumerate(columns):\n",
        "  for j in range(2):\n",
        "    if j==0:\n",
        "      IQR_plus = stat_train.loc['25%',col]+(stat_train.loc['75%',col]\\\n",
        "                                                   -stat_train.loc['25%',col])*1.5\n",
        "      res = len(X_train.query('{0} > @IQR_plus and status == \"closed\"'.format(col)))\\\n",
        "      /len(X_train.query('{0} > @IQR_plus'.format(col)))\n",
        "      print(f'Доля стартапов которы {s[i][0]} {round(IQR_plus,0)} {s[i][1]} и '\\\n",
        "            f'закрыты для тренировочны датасета :{round(res*100,2)}%.')\n",
        "    else:\n",
        "      IQR_plus = stat_test.loc['25%',col]+(stat_test.loc['75%',col]\\\n",
        "                                                   -stat_test.loc['25%',col])*1.5\n",
        "      res = len(X_test.loc[index_closed_test,:].query('{0} > @IQR_plus'.format(col)))\\\n",
        "      /len(X_test.query('{0} > @IQR_plus'.format(col)))\n",
        "      print(f'Доля стартапов которы {s[i][0]} {round(IQR_plus,0)} {s[i][1]} и '\\\n",
        "            f'закрыты для тестовой датасета :{round(res*100,2)}%.')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p71zbnIUBRZu"
      },
      "source": [
        "Например, можно подумать, что если стартап уже долго существовали, прошла много раундов или заработала много денег, у неё меньше шанс закрывается. Меньшее доли для выбросов выгладить  правильно для тренировочной выборки, однако для тестового набора данных сохраняется баланс 50%-50%, что выглядит подозрительно. Это как будто тестовое датасет содержаеть особые случаи и не отражает реальность.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vQDHvhB8w8d"
      },
      "source": [
        "# Расспределение целевого признака"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bqpj7Mcu8w8e"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train['status'].value_counts(normalize=True), y_test['status'].value_counts(normalize=True)]\n",
        "\n",
        "sample_type = [' в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "\n",
        "    sns.barplot(x=dataframe.index, y=dataframe, hue=dataframe.index, ax=axes[i])\n",
        "\n",
        "    axes[i].set_title(f'Распределение доля {sample_type[i]}')\n",
        "    #axes[i].set_xticklabels(['Работает', 'Закрыт']);\n",
        "    axes[i].set_xlabel('Стартап работает ли ?');\n",
        "    axes[i].set_ylabel('Доли');\n",
        "    axes[i].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IJNfpg08w8f"
      },
      "source": [
        "Мы замечаем огромный дисбаланс в вашем наборе обучающих данных (около 90%–10%), как мы и предвидели в части исследования недостающих данных. Напротив, он хорошо сбалансирован в наборе тестовых данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_z1FYNJ8w8g"
      },
      "source": [
        "## Исследованние распеделения количеств значений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o65iMI1D8w8h"
      },
      "source": [
        "## Распеделенние общего сбора средств"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VsoClza8w8i"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = ['в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "\n",
        "    if i == 0:\n",
        "        sns.histplot(x=dataframe.query('funding_total_usd < 5.000000e+06')['funding_total_usd'], color = 'skyblue',hue=dataframe['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "    else:\n",
        "        sns.histplot(x=dataframe.query('funding_total_usd < 5.000000e+06')['funding_total_usd'], color = 'skyblue',hue=y_test['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "\n",
        "    axes[i].set_title(f'Распределение общего сбора средстов {sample_type[i]}')\n",
        "\n",
        "    axes[i].set_xlabel('Общий сбор средств');\n",
        "    axes[i].set_ylabel('Плотность распределения');\n",
        "    axes[i].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxOWEoQZ8w8l"
      },
      "source": [
        "Нам пришлось исползовать заглушку, чтобы остронит выбросов. Мы видим, что график для теста и тренировочной датасета выглядит одинаково. Распределение как распределение Пуассона. Можно сказать что этот признак почти не влияет в цедевое признак для тестовой датасета. Ну видно в первом графике что болшее стартапа закрылись когда мало денег зарабатывали."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6OzAikL8w8r"
      },
      "source": [
        "## Распеделенние продолжительность жизни"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaAvuT0Z8w8s"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = ['в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "\n",
        "    if i == 0:\n",
        "        sns.histplot(x=dataframe['lifetime'], color = 'skyblue',hue=dataframe['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "    else:\n",
        "        sns.histplot(x=dataframe['lifetime'], color = 'skyblue',hue=y_test['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "\n",
        "    axes[i].set_title(f'Распределение продолжительность жизни {sample_type[i]}')\n",
        "\n",
        "    axes[i].set_xlabel('Продолжительность жизни');\n",
        "    axes[i].set_ylabel('Плотность распределения');\n",
        "plt.grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mW-mStI_0bJu"
      },
      "source": [
        "Здесь графики совсем не похожы, и мы можем увидеть влияние продолжительности жизни на целевой признак во первом датасете.\n",
        "\n",
        "Напротив, мы не можем провести различие между двумя классами, и понимать кто живут дольше во втором графике. Мы видим, что в тестовом наборе данных признак \"lifetime\" почти не влияет на целевую переменную.\n",
        "\n",
        "Мы говорили что болинство стартапов не живуть болшее 5 лет, и мы видим в обойх графике что это может правда так как у болшиньсто стартапов продолжительность жизни меншее 1825 дней.\n",
        "\n",
        "Ну сдезсь сложно осудить так как многих стартапов у которых есть меншее 5 летов. Можеть бы много из них будеть закрываеться скоро.\n",
        "\n",
        "\n",
        "Но есть и кое-что еще, есть разница между датой основания и датой первого финансирования. Мы это не можем проверит в тестовом датасете потому не даты основании ну давайте проверяем с тренировочноы выборком."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8Scxq4xo9ig"
      },
      "outputs": [],
      "source": [
        "X_train['diff'] = (X_train['first_funding_at']-X_train['founded_at']).dt.days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLG9BPlZpOp5"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "\n",
        "sns.histplot(x=X_train.query('0 < diff < 2500')['diff'],hue=X_train['status'], \\\n",
        "hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes)\n",
        "\n",
        "axes.set_title(f'Распределение разница между датой основаной и даты первого финансировании')\n",
        "\n",
        "axes.set_xlabel('Разница между датой основаной и даты первого финансировании');\n",
        "axes.set_ylabel('Плотность распределения');\n",
        "axes.grid();\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rekCumEGr2Cf"
      },
      "source": [
        "Мы ясно видим, что у большинства стартапов первый раунд финансирования состоялся менее чем через 750 дней после их основания, то есть примерно через два года. Мы ясно видим, что здесь большая часть стартапов закончилась провалом. Однако по прошествии двух лет, меньше компаний начинают свое финансирование, но и среди них меньше неудачных стартапов, возможно, потому, что им потребовалось больше времени на подготовку. Гипотеза: Увеличивает ли более длительное время предварительной подготовки шансы стартапа на успех?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8jkD-NYr26O"
      },
      "source": [
        "## Распеделенние доли перед раудом и последннии рауды"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NN1PaMb6rNnr"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = ['в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "\n",
        "    if i == 0:\n",
        "        sns.histplot(x=dataframe.query('pre_seed_last_round > 0 and pre_seed_last_round < 1')['pre_seed_last_round'], color = 'skyblue',hue=dataframe['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "    else:\n",
        "        sns.histplot(x=dataframe.query('pre_seed_last_round > 0 and pre_seed_last_round < 1')['pre_seed_last_round'], color = 'skyblue',hue=y_test['status'], \\\n",
        "                     hue_order=['operating', 'closed'], stat='density', common_norm=False, ax=axes[i])\n",
        "\n",
        "    axes[i].set_title(f'Распределение доли временни перед первом рауды и после плоседнного {sample_type[i]}')\n",
        "\n",
        "    axes[i].set_xlabel('Доли временние перед первом рауды и после последнного');\n",
        "    axes[i].set_ylabel('Плотность распределения');\n",
        "    axes[i].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-XI3d7xwBdr"
      },
      "source": [
        "На первом графике мы видим компание, у которие было меньше времени на подготовку, и к последнему раунду склонялись к закрытию. На втором графике, опять же, поведение двух классов очень близко, поэтому трудно сказать как признак 'pre_seed_last_round' являет на целевую перемеррую."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D6HMV-dmT15"
      },
      "source": [
        "Мы заметили некоторые аномалии, когда дата первого раунда наступала после даты основания. Это звучит невозможно. Мы можем думать их убирать."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CtbX8fXim_W0"
      },
      "outputs": [],
      "source": [
        "X_train.query('first_funding_at < founded_at')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q96kgmmF8w9A"
      },
      "source": [
        "# Исследованние распеделения категориального значения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6jq_-Jd8w9B"
      },
      "source": [
        "## Распеделенние количество раунды финансирования"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p34KwdLS8w9C"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = [' в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "\n",
        "    if i == 0:\n",
        "         sns.countplot(x=dataframe['funding_rounds'], hue=dataframe['status'], hue_order=['operating', 'closed'], stat='percent', ax=axes[i]);\n",
        "    else:\n",
        "\n",
        "        sns.countplot(x=dataframe['funding_rounds'], hue=y_test['status'], hue_order=['operating', 'closed'], stat='percent', ax=axes[i]);\n",
        "\n",
        "    axes[i].set_title(f'Распределение количество раунды финансирования {sample_type[i]}')\n",
        "\n",
        "    axes[i].set_xlabel('Раунды финансирования');\n",
        "    axes[i].set_ylabel('Количество');\n",
        "    axes[i].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkOqC9iwOm3p"
      },
      "source": [
        "Очевидно, что в первом раунде будет больше компаний, потому что это первый и самый простой раунд для входа, но, вероятно, один из самых трудных для выхода, поскольку репутация компании еще не создана. Конечно, по мере увеличения количества раундов стартапов становится все меньше и меньше. К сожалению, мы почти не видим влияния количества раундов на классы целевой переменной в втором графике.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMWByg0D8w9E"
      },
      "source": [
        "## Распеделенние частота категорий"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ELCLitn8w9E"
      },
      "outputs": [],
      "source": [
        "fi, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 7.5))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = [' в тренировчне выборке', 'в тестовое выборке']\n",
        "\n",
        "\n",
        "for i, dataframe in enumerate(dataframes):\n",
        "    if i == 0:\n",
        "        list_cat = dataframe['subcategories'].value_counts().index.to_list()[:50]\n",
        "        index_cat = dataframe.query('subcategories in @list_cat').index.to_list()\n",
        "\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe.loc[index_cat,'subcategories'], \\\n",
        "                      order=dataframe.loc[index_cat,'subcategories'].value_counts()[:50].index, hue=dataframe['status'], \\\n",
        "                      hue_order=['operating', 'closed'], stat='percent', ax=axes[i]);\n",
        "    else:\n",
        "        list_cat = dataframe['subcategories'].value_counts().index.to_list()[:50]\n",
        "        index_cat = dataframe.query('subcategories in @list_cat').index.to_list()\n",
        "\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe.loc[index_cat,'subcategories'], \\\n",
        "                      order=dataframe.loc[index_cat, 'subcategories'].value_counts()[:50].index, hue=y_test['status'], \\\n",
        "                      hue_order=['operating', 'closed'], stat='percent', ax=axes[i]);\n",
        "\n",
        "    axes[i].set_title(f'Распределение частота категорей {sample_type[i]}')\n",
        "    axes[i].tick_params(axis='x', labelrotation=90)\n",
        "    axes[i].set_xlabel('Категорий');\n",
        "    axes[i].set_ylabel('Частота');\n",
        "    axes[i].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP89gYtidbwo"
      },
      "source": [
        "Стартапы больше всего работают в сфере Internet & E-commerce & Mobileв, затем Hardware, Software and Apps, а затем Business and professional Services. Мы ясно видим дисбаланс наших данных в тренировочном датасета. Во втором графике, разница между работающейвся компанией и закрытой компанией очень мала."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EOZ85cH8w9M"
      },
      "source": [
        "## Распеделенние местоположение"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIbbwhtx8w9N"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 15))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = [' в тренировчне выборке', 'в тестовое выборке']\n",
        "columns = ['countries', 'states', 'regions', 'cities']\n",
        "column_names = ['страны', 'штаты', 'регионы', 'городы']\n",
        "column_names_2 = ['странах', 'штатах', 'регионах', 'городах']\n",
        "\n",
        "\n",
        "for i, col in enumerate(columns):\n",
        "  for j, dataframe in enumerate(dataframes):\n",
        "    if j == 0:\n",
        "        list_coun = dataframe[col].value_counts().index.to_list()[:25]\n",
        "        index_coun = dataframe.query('{0} in @list_coun'.format(col)).index.to_list()\n",
        "\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe.loc[index_coun,col], \\\n",
        "                      order=dataframe.loc[index_coun,col].value_counts()[:25].index, hue=dataframe['status'], \\\n",
        "                      hue_order=['operating', 'closed'], stat='percent', ax=axes[2*i+j]);\n",
        "    else:\n",
        "        list_coun = dataframe[col].value_counts().index.to_list()[:25]\n",
        "        index_coun = dataframe.query('{0} in @list_coun'.format(col)).index.to_list()\n",
        "\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe.loc[index_coun,col], \\\n",
        "                      order=dataframe.loc[index_coun,col].value_counts()[:25].index, hue=y_test['status'], \\\n",
        "                      hue_order=['operating', 'closed'], stat='percent', ax=axes[2*i+j]);\n",
        "\n",
        "    axes[2*i+j].set_title(f'Распределение стартапо в {column_names[i]} {sample_type[j%2]}')\n",
        "    axes[2*i+j].tick_params(axis='x', labelrotation=90)\n",
        "    axes[2*i+j].set_xlabel(f'{column_names[i]}');\n",
        "    axes[2*i+j].set_ylabel('Частота');\n",
        "    axes[2*i+j].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8H6UZJqfbcI"
      },
      "source": [
        "Здесь мы также видим, что Америка является наиболее представленной страной, Калифорния - наиболее представленным штатом, Район залива Сан-Франциско - наиболее представленным регионом и  Misc. - наиболее представленным городом,  ну должно было бы Сан-Франциско.Потомучто понятно сейчас что большая часть стартапов из наших наборов данных - из Кремниевой долины. Здесь кокда мы групмровали на групы Misc. мы исказили данные. Например, для признак 'regions', 'Misc.' второй.\n",
        "\n",
        "Однако мы замечаем, что чем больше географическая зона, тем меньше группа 'Misc.' это означает, что страны — наш более надежный признак для локализации.\n",
        "Меньшие зоны, более дата изскаженое в основном регионы и города. Hам пришлось сгруппировать реже встречающиеся регионы и города вместе, чтобы избежать переобучения нашей модели из-за слишком большого количества одиночных значений, ну видно что мы сейчас не можем их исползовать для МО.\n",
        "\n",
        "Однако это не проблемы, потому что все эти признаки повторяют тот же информации для местоположение. Тогда лучее взять страну так как у него меншее пропусков чем других признаков для местоположении."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgFotfFW-ojY"
      },
      "source": [
        "## Распеделенние по временни"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQfsNLPW8w9Z"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(15, 15))\n",
        "\n",
        "axes = axes.flatten()\n",
        "\n",
        "dataframes = [X_train, X_test]\n",
        "\n",
        "sample_type = [' в тренировчне выборке', 'в тестовое выборке']\n",
        "columns = ['first_funding_year', 'last_funding_year', 'first_funding_month', 'last_funding_month']\n",
        "column_names = ['финансирование первого года', 'финансирование последного года', \\\n",
        "                'финансирование первого месяца', 'финансирование последного месяца']\n",
        "in_out = ['начинают свой финансовый раунд', 'завершают свой финансовый раунд']\n",
        "\n",
        "for i, col in enumerate(columns):\n",
        "  for j, dataframe in enumerate(dataframes):\n",
        "    if j == 0:\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe[col], \\\n",
        "                      order=range(1,13) if i>1 else dataframe[col].value_counts().index, hue=dataframe['status'], \\\n",
        "                      hue_order=['operating', 'closed'], \\\n",
        "                      stat='percent', ax=axes[2*i+j]);\n",
        "    else:\n",
        "\n",
        "        sns.countplot(data=dataframe, x=dataframe[col], \\\n",
        "                      order=range(1,13) if i>1 else dataframe[col].value_counts().index, hue=y_test['status'], \\\n",
        "                      hue_order=['operating', 'closed'], \\\n",
        "                      stat='percent', ax=axes[2*i+j]);\n",
        "\n",
        "    axes[2*i+j].set_title(f'Распределение частота стартапов которие {in_out[j%2]} {sample_type[j%2]}')\n",
        "    axes[2*i+j].tick_params(axis='x', labelrotation=90)\n",
        "    axes[2*i+j].set_xlabel(f'{column_names[i]}');\n",
        "    axes[2*i+j].set_ylabel('Частота');\n",
        "    axes[2*i+j].grid();\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INKqoabImvky"
      },
      "source": [
        "Мы говорили что болинство стартапов не живуть болшее 5 лет, видно здесь что эьо сложно осудить так у многих начиналось финансированое недавно по сравню дата выпускы датасета. Мы можем судить только 43% данных по этой гипотезе."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C62M6Y8vnZ82"
      },
      "outputs": [],
      "source": [
        "len(X_train[X_train['first_funding_year']<2012])/len(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqRySayj-BF4"
      },
      "source": [
        "57% наших данных — это компании, у которых все еще могут быть закрыты шансы в соответствии с упомянутым нами состоянием."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WLeS3VB-JSU"
      },
      "outputs": [],
      "source": [
        "len(X_test[X_test['first_funding_year']<2012])/len(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pt81Z7MhAMzw"
      },
      "source": [
        "## Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THlitFNOAUcy"
      },
      "source": [
        "Похоже, что большая часть нашего распределения не является нормальным распределением, а распределением Пуассона, поскольку здесь задействовано время.\n",
        "\n",
        "Мы отметили во время исследовательского аналз данных много выбросов, много компаний, которые зарабатывают много денег, и компаний, которые имеют очень долгую жизнь, и они не обязательно одинаковы. Компании у которых много денег, как правило, затмевают молодые стартапы и стартапы с гораздо меньшими деньгами. Однако мы не можем от этих выбросов избавиться, эти стартапы не являются аномалией.\n",
        "\n",
        "Следующее, мы замечали что в наборе тренировоных данных, признак \"lifetime\" оказалось большое влияние на целевую переменную, чем total_funding_year.\n",
        "\n",
        "Мы оставили это в конце, но самое важное, что мы заметили, это то, что мы видели ранее при EDA: дисбаланс нашей целевой переменной в тренировочном данных и чрезвычайно хорошо сбалансированной классов в целевой переменной в тестовом датасета.\n",
        "\n",
        "Дисбаланс 90%-10% в наборе тренировочных данных может стать проблемой, которую можно решить с помощью некоторых методов, таких как SMOTE или добавление опции class_weight в наши модели, чтобы модель не слишком отдавала предпочтение к крупному классу \"operating\".\n",
        "Хорошо сбалансированные классы в нашем тестовом наборе данных также являются проблемой, поскольку нашей модели тоже не за что будет 'захватывать'. Например, мы видели среди выбросов что баланс классов 50-50 соханилось. В ходе изучения распределения различных признаков мы заметили, что большую часть времени, это хорошый баланс классов тоже соханилось. Этот слишком хороший баланс будет проблемой для модели, поскольку у нее нет никакого способа различить разницу между классами.\n",
        "\n",
        "Проблема не в том, что в нашем тестовом наборе данных было,баланс классов 50-50, а в том, что эти классы ведут себя одинаково в зависимости от разных признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Oev44Z8w9i"
      },
      "source": [
        "# Корреляционный анализ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTAloxPU8w9n"
      },
      "outputs": [],
      "source": [
        "# Let's prepare our dataset for the modelisation\n",
        "X_train_corr = X_train.drop(['name', 'category_list','country_code', 'state_code', 'region', 'city', \\\n",
        "                          'founded_at','first_funding_at','last_funding_at', 'closed_at'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c2hMlfWq8w9o"
      },
      "outputs": [],
      "source": [
        "# Let's prepare our dataset for the modelisation\n",
        "X_test_corr = X_test.drop(['name', 'category_list','country_code', 'state_code', 'region', 'city', \\\n",
        "                        'first_funding_at','last_funding_at'], axis=1)\n",
        "# Let's add the target to our dataframe\n",
        "X_test_corr['status'] = y_test['status']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0iWVFLMk8w9p"
      },
      "outputs": [],
      "source": [
        "interval_cols = ['funding_total_usd', 'lifetime',  'first_funding_year', 'last_funding_year', 'pre_seed_last_round', 'diff']\n",
        "\n",
        "# Вычисление матрицы корреляции с использованием phik\n",
        "corr_matrix = X_train_corr.phik_matrix(interval_cols=interval_cols)\n",
        "\n",
        "# Визуализация матрицы\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='crest');\n",
        "plt.title('Phi_K Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYcMBXVY_7Au"
      },
      "source": [
        "Мы укрепили признак 'diff' зная что мы его не можем исползовать, ну просто видеть как он являеться на целевое признак.\n",
        "\n",
        "Если мы посмотрим на матрицу, то увидим, что 'lifetime' оказывает наибольшее влияние на целевую переменную. Только fund_total_usd вообще не оказывает никакого влияния на целевую переменную. Однако 'subcategories', 'first_funding_month' и 'last_funding_round_month' имеют очень низкое влияние."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAXP5ro48w9q"
      },
      "outputs": [],
      "source": [
        "interval_cols = ['funding_total_usd', 'lifetime',  'first_funding_year', 'last_funding_year', 'pre_seed_last_round']\n",
        "\n",
        "# Вычисление матрицы корреляции с использованием phik\n",
        "corr_matrix = X_test_corr.phik_matrix(interval_cols=interval_cols)\n",
        "\n",
        "# Визуализация матрицы\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='crest');\n",
        "plt.title('Phi_K Correlation Matrix')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aOCxzyMO1Fk"
      },
      "source": [
        "В нашем тренировочной данных нет действительно влиятельных переменных, что является проблемой, поскольку мы можем не получить хорошый результат, когда запустим нашу модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQb8L6qlKnFb"
      },
      "source": [
        "## Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtEh5kD3Ksx8"
      },
      "source": [
        "Так как все признаки для местоположении коллинеарный, мы выбрали только один - 'countries'. У этого признакы по сравню 'states', 'regions' и 'cities' меншее других, пропусков и меншее других унникальние значение. Так будет ещё меншее шансы получит искаженные данные  после  метода Imputer.\n",
        "\n",
        "Для временни мы отобрали признак : 'first_funding_year' и 'last_funding_year'. Не выбрали 'last_funding_month' и 'last_funding_month' из за коллинеарност.\n",
        "\n",
        "Вот наши тобранные признаки:\n",
        "\n",
        "- lifetime\n",
        "- countries\n",
        "- funding_total_usd\n",
        "- funding_rounds\n",
        "- last funding year\n",
        "- last funding month\n",
        "- subcategories\n",
        "- pre_seed_last_round\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4GPTtsj8w9s"
      },
      "source": [
        "# Пайплайн"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCcwwh2c8w9t"
      },
      "source": [
        "Мы увидели, что наша целевой признак несбалансирован, и нам следует использовать метод oversampling, например SMOTETomek (SMOTENC из-за этого наш расчет приостоновился). Однако обсуждалось, что такая техника не так эффективна, и люди склонны компенсировать дисбаланс своими данными с помощью алгоритма повышения, что мы и собираемся сделать с использованием CatBoost.\n",
        "\n",
        "Что касается кодировки, поскольку у нас много одиночных значений, нам нужно как следует подумать, как их закодировать. Чтобы избежать размерного проклятия, у нас есть большой выбор кодировщика: frequency encoder, target encoder, hashing encoder. Поскольку мы собираемся использовать CatBoost для нашей модели машинного обучения, мы собираемся использовать кодировщик CatBoost, целевой кодировщик, который хорошо работает в нашем случае.\n",
        "\n",
        "По поводу пропусков, мы будем исползовать SimpleImputer с стратегой 'most frequent' для категорялных значеных и для количественных значеных KNNImputer.\n",
        "\n",
        "Для моделировании мы будем исползовать :\n",
        "- LogisticRegression\n",
        "- CatboostClassifier\n",
        "- BalancedRandomForestClassifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyPuo2XRliFi"
      },
      "source": [
        "Дупликаты взяты из раундов финансирования, поэтому мы не собираемся их удалять."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnmgzdCp8w9x"
      },
      "outputs": [],
      "source": [
        "# Let's prepare dataset for the modelisation\n",
        "X_train_m = X_train_corr.drop(['status', 'last_funding_year', 'last_funding_month', 'diff',\\\n",
        "                                'regions', 'cities', 'states'], axis=1)\n",
        "\n",
        "X_test_m = X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zp_6o-h48w9y"
      },
      "outputs": [],
      "source": [
        "# Подготовим наш целевой признак к моделированию\n",
        "y_train_m = X_train_corr['status']\n",
        "\n",
        "# Констант\n",
        "RANDOM_STATE=42\n",
        "\n",
        "# создаём списки с названиями признаков\n",
        "boost_columns_1 = ['countries', 'subcategories','first_funding_year', 'first_funding_month']\n",
        "\n",
        "num_columns = ['lifetime','funding_total_usd', 'funding_rounds', 'pre_seed_last_round']\n",
        "\n",
        "#cnt_encoder = ce.count.CountEncoder()\n",
        "cbe_encoder = ce.cat_boost.CatBoostEncoder()\n",
        "loo_encoder = ce.leave_one_out.LeaveOneOutEncoder()\n",
        "\n",
        "# Кодируем нашу целевую переменную\n",
        "le = LabelEncoder()\n",
        "y_train_le = le.fit_transform(y_train_m)\n",
        "y_test_le = le.transform(y_test['status'])\n",
        "\n",
        "# создаём пайплайн для категорильного значения\n",
        "boost_pipe_1 = Pipeline([\n",
        "    ('imp_1', SimpleImputer(missing_values=np.nan, strategy='most_frequent')),\n",
        "    ('cboost', cbe_encoder)\n",
        "])\n",
        "\n",
        "num_pipe = Pipeline([\n",
        "    ('imp', KNNImputer(n_neighbors=5)),\n",
        "    ('scal', MinMaxScaler())#,\n",
        "    #('poly', PolynomialFeatures(2, include_bias=False))\n",
        "])\n",
        "\n",
        "# создаём общий пайплайн для подготовки данных\n",
        "data_preprocessor = ColumnTransformer(\n",
        "    [('boost_1', boost_pipe_1, boost_columns_1),\n",
        "     ('num', num_pipe, num_columns)\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLdm7c3o8w90"
      },
      "outputs": [],
      "source": [
        "smote_tomek = SMOTETomek(sampling_strategy='auto')\n",
        "\n",
        "\n",
        "# создаём итоговый пайплайн: подготовка данных и модель\n",
        "pipe = Pipeline([\n",
        "    ('preprocessor', data_preprocessor),\n",
        "    ('smote', smote_tomek),\n",
        "    ('models', [LogisticRegression(random_state=RANDOM_STATE, solver='liblinear',)])\n",
        "])\n",
        "\n",
        "param_grid = [\n",
        "    # словарь для модели LogisticRegression()\n",
        "      {\n",
        "      'models': [LogisticRegression(random_state=RANDOM_STATE,solver='liblinear',)],\n",
        "      'models__C': [0.01, 0.1, 1, 10, 100],\n",
        "      'models__penalty': ['l1', 'l2'],\n",
        "      'models__class_weight':['balanced'],\n",
        "      'preprocessor__boost_1': [cbe_encoder, loo_encoder],\n",
        "      'preprocessor__num__scal': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
        "      'smote':[SMOTETomek(sampling_strategy='all')]\n",
        "    },\n",
        "\n",
        "   # dict for CatBoostClassifier()\n",
        "    {'models':[CatBoostClassifier(loss_function='Logloss', auto_class_weights='Balanced', \\\n",
        "                                   random_state=RANDOM_STATE)],\n",
        "    'models__iterations': [100, 200],\n",
        "    'models__learning_rate': [0.01, 0.1],\n",
        "    'models__depth': [3, 6, 9],\n",
        "    'preprocessor__boost_1': [cbe_encoder, loo_encoder],\n",
        "    'preprocessor__num__scal': [StandardScaler(), MinMaxScaler(), RobustScaler()],\n",
        "    'smote':[SMOTETomek(sampling_strategy='auto')]\n",
        "     },\n",
        "    # dict for BalancedRandomForestClassifier()\n",
        "      {'models':[BalancedRandomForestClassifier(replacement=True, sampling_strategy='all',\n",
        "                                                 random_state=RANDOM_STATE)],\n",
        "      'models__n_estimators': [25, 33, 41, 48, 56, 64],\n",
        "      'models__max_features': range(2,14),\n",
        "      'models__min_samples_split':range(2,14),\n",
        "      'models__min_samples_leaf':range(1,14),\n",
        "      'models__max_depth': range(2,14),\n",
        "      'models__bootstrap': [True, False],\n",
        "      'models__class_weight': ['balanced', 'balanced_subsample'],\n",
        "      'preprocessor__boost_1': [loo_encoder, cbe_encoder],\n",
        "      'preprocessor__num__scal': [StandardScaler(), MinMaxScaler(), RobustScaler()] ,\n",
        "      'smote':[SMOTETomek(sampling_strategy='all')]\n",
        "       }\n",
        "\n",
        "]\n",
        "randomized_search = RandomizedSearchCV(\n",
        "    pipe,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    random_state=RANDOM_STATE,\n",
        "    error_score=\"raise\",\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "randomized_search.fit(X_train_m, y_train_le)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb3xMGih8w94"
      },
      "outputs": [],
      "source": [
        "# Итог гиперпараметр тюнинг\n",
        "report_randomised_search = pd.DataFrame(randomized_search.cv_results_)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "report_randomised_search.sort_values('rank_test_score', ascending=True)[['param_preprocessor__num__scal', \\\n",
        "                                                                          'param_preprocessor__boost_1', \\\n",
        "                                                                          'param_models', 'params', \\\n",
        "                                                                          'mean_test_score', 'std_test_score', \\\n",
        "                                                                          'rank_test_score']].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LUlNva_r8w96"
      },
      "outputs": [],
      "source": [
        "model = randomized_search.best_estimator_\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGpM_pT78w-B"
      },
      "source": [
        "# Анализ важности признаков"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hPuI56R-JgIC"
      },
      "source": [
        "## С помощю SelecKBest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfRJ-aC38w98"
      },
      "outputs": [],
      "source": [
        "# Let's prepare our training dataset with the data_preprocessort pipe\n",
        "X_train_pipe = data_preprocessor.fit_transform(X_train_m, y_train_le)\n",
        "#X_train_pipe_column_names = data_preprocessor.get_feature_names_out()\n",
        "X_train_pipe_column_names = boost_columns_1 + num_columns\n",
        "X_train_pipe = pd.DataFrame(X_train_pipe, columns = X_train_pipe_column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EDDZfZVTiq7U"
      },
      "outputs": [],
      "source": [
        "# Let's prepare our test dataset with the data_preprocessort pipe\n",
        "X_test_pipe = data_preprocessor.transform(X_test_m)\n",
        "#X_test_pipe_column_names = data_preprocessor.get_feature_names_out()\n",
        "X_test_pipe_column_names = boost_columns_1 + num_columns\n",
        "X_test_pipe = pd.DataFrame(X_test_pipe, columns = X_test_pipe_column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBwqKW6V8w-B"
      },
      "outputs": [],
      "source": [
        "selector = SelectKBest(f_classif, k=8)\n",
        "\n",
        "# обучаем SelectKBest\n",
        "selector.fit(X_train_pipe, y_train_le)\n",
        "\n",
        "# сформируйте выборки с лучшими признаками\n",
        "features_names = X_train_pipe.columns[selector.get_support(indices=True)]\n",
        "X_train_new = X_train_pipe[list(features_names)]\n",
        "X_test_new = X_test_pipe[list(features_names)]\n",
        "#print(features_names)\n",
        "\n",
        "model_ = BalancedRandomForestClassifier(bootstrap=False, class_weight='balanced',\n",
        "                               max_depth=11, max_features=3,\n",
        "                               min_samples_leaf=12, min_samples_split=3,\n",
        "                               n_estimators=41, random_state=42,\n",
        "                               replacement=True, sampling_strategy='all')\n",
        "\n",
        "model_.fit(X_train_new, y_train_le)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liKPx2pU8w-C"
      },
      "outputs": [],
      "source": [
        "# отложим значения коэффициентов на графике\n",
        "coefficients = model_.feature_importances_\n",
        "features_importance = pd.DataFrame({'Features': features_names, 'Importance': np.abs(coefficients)})\n",
        "features_importance = features_importance.sort_values('Importance',ascending=True)\n",
        "print(features_importance)\n",
        "plot_features_importance = features_importance.plot(x='Features', \\\n",
        "                                                    y='Importance',\\\n",
        "                                                    kind='barh', figsize=(10, 6));\n",
        "plt.title('Важности признаков с методом SelectKBest'),\n",
        "plt.xlabel('Важность');\n",
        "plt.ylabel('Признаки');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auNl6jFGKiSE"
      },
      "source": [
        "С методом SKbest feature_importance видим что у нас\n",
        "\n",
        "1 очень важный признак:\n",
        "- продолжительност жизни\n",
        "\n",
        "1 важный признак:\n",
        "- год первого финансирования\n",
        "\n",
        "Есть 4 слабо влияющих признака, в порядке значимости:\n",
        "\n",
        "- общее финансирование\n",
        "- страны\n",
        "- катагорие\n",
        "- месяц первого финансирования\n",
        "\n",
        "Есть 1 слабо влияющих признака:\n",
        "- количество раудов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilw_bcNrKHss"
      },
      "source": [
        "## С помощю SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKsjTTjX8w-G"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(model_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EU7HiN3h8w-H"
      },
      "outputs": [],
      "source": [
        "shap_values = explainer(X_train_pipe.sample(frac=0.1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wyU74Wlk8w-J"
      },
      "outputs": [],
      "source": [
        "shap.plots.beeswarm(shap_values[:,:,0], max_display=8)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shap.plots.beeswarm(shap_values[:,:,1], max_display=8)"
      ],
      "metadata": {
        "id": "l3l-HfuBxDdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Порядок важности функций практически такой же, как и в SelectKbest. На графиках SHAP для нашего класса 0 мы видим, что большинство признаки имеют тенденцию являет на класс 0 (отрицательные значения SHAP), наш класс меньшинства."
      ],
      "metadata": {
        "id": "eN5EFiknwiBw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJL44lZZT9Lj"
      },
      "source": [
        "# Резултать исследованние"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZrQ00q_O_MU"
      },
      "source": [
        "## Предсказание с самой лучшей моделей"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biVcm7xF8w-P"
      },
      "outputs": [],
      "source": [
        "# Наш пердсказание\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vV-lsi3K8w-Q"
      },
      "outputs": [],
      "source": [
        "# Вероятность предсказания\n",
        "y_pred_proba = model.predict_proba(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61aVSShh8w-R"
      },
      "outputs": [],
      "source": [
        "#\n",
        "y_pred_proba_one = y_pred_proba[:,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "raz6cBzN8w-T"
      },
      "outputs": [],
      "source": [
        "print('Площадь ROC-кривой:', roc_auc_score(y_test_le, y_pred_proba_one))\n",
        "\n",
        "print(f'Метрика Recall на тестовой выборке: {recall_score(y_test_le, y_pred)}')\n",
        "print(f'Метрика Precision на тестовой выборке: {precision_score(y_test_le, y_pred)}')\n",
        "\n",
        "cm = confusion_matrix(y_test_le, y_pred)\n",
        "cm_plot = sns.heatmap(cm, annot=True, fmt='d', cmap='crest')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N58OkX5b8w-T"
      },
      "outputs": [],
      "source": [
        "# Наш метрик f1-score\n",
        "f1_score(y_test_le, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Истинно отрицательный = 689, стартапы, которым модель предсказывала провал, но которые на самом деле потерпели неудачу.\n",
        "\n",
        "Истинно положительный = 5937, стартапы, которые, по прогнозам модели, не потерпят неудачу, и которые ещё работает.\n",
        "\n",
        "Ошибка первого рода = 5801, стартапы, которые, по прогнозам модели, все еще работают, но в конце концов закрылись.\n",
        "\n",
        "Ошибка второго рода = 698, стартапы, которые модель предсказывает закрытие, но они все еще работают.\n",
        "\n",
        "Без сюрпризов: модель хорошо предсказывает класс большинства из тренировочной набора, но не может предсказать хорощо класс меньшинства. Модел действительно отдает предпочтение классу большинства, вероятно, из-за дисбаланса в тренировочной наборе.\n",
        "\n",
        "Результат довольно плохой, поскольку у нас много ошибок первого порядка, которы мы хотели минимизировать. Здесь, модель не смог предсказать, что 5801 стартап закроются. Здесь виновата не только модель, но и тестовый набор данных, который, похоже, не отражает реальности."
      ],
      "metadata": {
        "id": "TdLAljsT0HcH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_TYYN9n8w97"
      },
      "source": [
        "## Dummy Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bG_oNZUmQGy8"
      },
      "source": [
        "Нам нужно посмотреть, дала ли наша модель лучший результат, чем  dummy classifier на тестовом наборе данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIK-bgZW8w9-"
      },
      "outputs": [],
      "source": [
        "dclf = DummyClassifier(random_state = RANDOM_STATE)\n",
        "dclf.fit(X_train_pipe, y_train_le)\n",
        "y_pred_dummy = dclf.predict(X_test_pipe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2K0VZa0o8w-A"
      },
      "outputs": [],
      "source": [
        "f1_score(y_test_le, y_pred_dummy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DeL231zQgXY"
      },
      "source": [
        "Это нехорошо, dummy classifier дал лучший результат. Давайте посмотрим, что дает модулю pycaret, чтобы увидеть, как далеко мы находимся."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2W-mK7vvRupy"
      },
      "source": [
        "## Pycaret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLOP4ujb8w-X"
      },
      "outputs": [],
      "source": [
        "# Метод нормализации ç — z-оценка\n",
        "# Метод дисбаланса ç — SMOTE\n",
        "# Кодировщиком по умолчанию является target_encoder от category_encoders\n",
        "# По умолчанию StratifiedKfold на 10\n",
        "s1 = classification.setup(X_train_m, target=y_train_m, normalize=True, fix_imbalance=True, session_id=123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0W0ydNd8w-Y"
      },
      "outputs": [],
      "source": [
        " # Сравнение всех моделей, чтобы определить, какая из них лучше\n",
        "best = classification.compare_models()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiuPpORw8w-Y"
      },
      "outputs": [],
      "source": [
        "# показать лучшую модель\n",
        "print(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_-uNfan8w-Z"
      },
      "outputs": [],
      "source": [
        "## показать пайплайн\n",
        "classification.finalize_model(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxrnlLig8w-a"
      },
      "outputs": [],
      "source": [
        "classification.evaluate_model(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_PWKArV8w-b"
      },
      "outputs": [],
      "source": [
        "# Прогнозируем набор тестовых данных pycaret\n",
        "classification.predict_model(best)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVHR57t78w-c"
      },
      "outputs": [],
      "source": [
        "# Что бы предсказать от нашего тестовой датасета\n",
        "classification.predict_model(best, X_test_m)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR8apdwBuIYQ"
      },
      "source": [
        "# Обшее Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVpwQSZduLkl"
      },
      "source": [
        "Одной из основных трудностей был размер набора данных: в наших тренировочных данных было более 52 000 объектов и более 13000 объектов в тестовом датасете.\n",
        "\n",
        "Наша целевая переменная является двоичной, класс 0 был 'closed', а 'operating' — класс 1. Мы заметили некоторые пропусков среди шестами признаками: 'total_funding_usd', 'category_list', 'country_code', 'state_code', 'region' и 'city'. Последние четыре — это значения местоположеннии, которые дают нам избыточную информацию. Когда мы начали изучать дубликаты, из-за большого количества объектов нам пришлось сгруппировать те, которые реже появлялись, чтобы ограничить возможное переобучениое нашей модели.\n",
        "\n",
        "Мы также создали две признаки: одну, которая была в данных, но отсутствовала в тренировочном данных — 'продолжительность жизни', и другую, которую я создал, чтобы принять во внимание время до первого раунда, потому что некоторые стартапы терпели неудачу, потому что они были недостаточно подготовлены. и мы могли бы подумать, что, возможно, время сыграло роль в недостаточней подготовки.\n",
        "\n",
        "В ходе EDA мы заметили, что влияние признаков оказали незначительное на целевую переменную, в основном для тестового набора данных. «Продолжительность жизни» была наиболее влиятельной на целевую переменную в трениворочном наборе.\n",
        "\n",
        "Согласно статистике, 70% стартапов закрываются со второго по пятый год раунда финансирования, но мы заметили, что около 53% данных составляют стартапы моложе пяти лет.\n",
        "\n",
        "Мы также замечали дисбаланс целевой переменной в пропорции 90%–10% в наборе тренировочных данных. Это вынуждает нас использовать какой-то специальный метод, такой как SMOTETomek, или использовать атрибут class_weight нашей модели, чтобы преодолеть это. Однако во втором наборе данных оба класса были почти идеально сбалансированы. Но проблема, которую мы увидели в EDA, заключается в том, что оба класса имели почти одинаковое поведение, что больше всего повлияло на результат нашего исследования (предсказание).\n",
        "\n",
        "Действительно, после настройки нашей пайплайны и использования её с RandomizedSearchCV с необходимыми параметрами (SimpleImputer, KNNImputer, catboost и кодировщик Leave_one_out, SMOTETomek) и тремя разными моделями машинного обучения (LogisticRegression, BalancedRandomForest и Catboost), мы обучили нашу модель и на ее основе получили нашу лучшую модель: BalancedRandomForest(). Выбор был сделан с помощью f1_score. Мы получили очень хороший результат: 98,3% заставили нас думать, что наша модель, вероятно, переобучило.\n",
        "\n",
        "Затем мы оценили наиболее важные функции нашей модели с помощью SKbest и SHAP и попытались увидеть, какие признаки мы могли бы удалить, чтобы повысить качество нашей модели. Однако после изучения или корреляции между признаками мы имеем правильный выбор признака.\n",
        "\n",
        "Затем мы применили модель к набору данных и получили 64,8%, что неудивительно. Dummy Classifier дал лучший результат 67,1%, но этого и следовало ожидать, если бы оба класса вели себя одинаково. Неудивительно, чтоDummy Classifier, основанный на этой основе, каждый класс ведет себя с одинаковой вероятностью.\n",
        "\n",
        "Затем мы используем pycaret, чтобы увидеть, каков был результат и какую модель он выбрал, чтобы увидеть, может ли он дать лучший результат. Лучшеe модель была Catboost, но она получила еще худший результат на f1 метрике, чем мы.\n",
        "\n",
        "Наверно нам понадобится еще один тестовы набор данных. Даже добавить другие признаки могут нас не спасти, потому что в тестовых наборе данных есть особый случай закрытых стартапов, текущий тестовый набор кажется не очень отражает реальность.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "databundleVersionId": 9232440,
          "sourceId": 83379,
          "sourceType": "competition"
        },
        {
          "datasetId": 2623903,
          "sourceId": 4484101,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30746,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}